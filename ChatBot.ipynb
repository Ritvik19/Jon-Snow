{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T18:11:02.391847Z",
     "start_time": "2019-07-29T18:11:00.276085Z"
    }
   },
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T18:11:02.448114Z",
     "start_time": "2019-07-29T18:11:02.439138Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('stopwords.txt') as f:\n",
    "    stopwords = f.readlines()\n",
    "    \n",
    "stopwords = set(map(lambda x: x.strip(), stopwords))|set([\"''\", \"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'herse', 'himse', 'itse', 'myse', \"n't\", 'need', 'sha', 'wo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T18:22:37.870032Z",
     "start_time": "2019-07-29T18:19:13.466735Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jon Snow: My name is Jon Snow. What do you want to know about?\n",
      "Google\n",
      "Jon Snow: I will answer your queries about Google. If you want to exit, type Bye!\n",
      "Who is the CEO of Google\n",
      "Jon Snow: sundar pichai was appointed ceo of google, replacing larry page who became the ceo of alphabet.\n",
      "some brands occupied by google\n",
      "Jon Snow: a google spokesman would not comment of the price.\n",
      "bye\n",
      "Jon Snow: Bye! take care..\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    query = input('Jon Snow: My name is Jon Snow. What do you want to know about?\\n')\n",
    "    raw = wikipedia.page(query).content\n",
    "\n",
    "    def tokenize(x):\n",
    "        return [token for token in word_tokenize(x) if re.match(r'\\w+', x)]\n",
    "    \n",
    "    raw=raw.lower()# converts to lowercase\n",
    "    content = ''\n",
    "    for sent in raw.split('\\n'):\n",
    "        if len(sent) > 0 and not sent.startswith('='):\n",
    "            content += sent +'\\n'\n",
    "    sent_tokens = sent_tokenize(content)\n",
    "    word_tokens = tokenize(raw)\n",
    "\n",
    "    GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\",)\n",
    "    GREETING_RESPONSES = [\"hi\", \"hey\", \"*nods*\", \"hi there\", \"hello\", \"I am glad! You are talking to me\"]\n",
    "\n",
    "\n",
    "\n",
    "    # Checking for greetings\n",
    "    def greeting(sentence):\n",
    "    #If user's input is a greeting, return a greeting response\n",
    "        for word in sentence.split():\n",
    "            if word.lower() in GREETING_INPUTS:\n",
    "                return random.choice(GREETING_RESPONSES)\n",
    "\n",
    "\n",
    "#     from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "        # Generating response\n",
    "    def response(user_response):\n",
    "        robo_response=''\n",
    "        sent_tokens.append(user_response)\n",
    "        TfidfVec = CountVectorizer(tokenizer=tokenize, stop_words=stopwords, binary=True)\n",
    "        tfidf = TfidfVec.fit_transform(sent_tokens)\n",
    "        vals = cosine_similarity(tfidf[-1], tfidf)\n",
    "        idx=vals.argsort()[0][-2]\n",
    "        flat = vals.flatten()\n",
    "        flat.sort()\n",
    "        req_tfidf = flat[-2]\n",
    "        if(req_tfidf==0):\n",
    "            robo_response=robo_response+\"I am sorry! I don't understand you\"\n",
    "            return robo_response\n",
    "        else:\n",
    "            robo_response = robo_response+sent_tokens[idx]\n",
    "            return robo_response\n",
    "\n",
    "\n",
    "    flag=True\n",
    "    print(\"Jon Snow: I will answer your queries about \"+query+\". If you want to exit, type Bye!\")\n",
    "\n",
    "    while(flag==True):\n",
    "        user_response = input()\n",
    "        user_response=user_response.lower()\n",
    "        if(user_response!='bye'):\n",
    "            if(user_response=='thanks' or user_response=='thank you' ):\n",
    "                flag=False\n",
    "                print(\"Jon Snow: You are welcome..\")\n",
    "            else:\n",
    "                if(greeting(user_response)!=None):\n",
    "                    print(\"Jon Snow: \"+greeting(user_response))\n",
    "                else:\n",
    "                    print(\"Jon Snow: \",end=\"\")\n",
    "                    print(response(user_response))\n",
    "                    sent_tokens.remove(user_response)\n",
    "        else:\n",
    "            flag=False\n",
    "            print(\"Jon Snow: Bye! take care..\")\n",
    "except wikipedia.DisambiguationError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
